{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86aa87f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee84e26",
   "metadata": {},
   "source": [
    "# Final Project: 2016 Voter Survey Data\n",
    "\n",
    "In this data set we will be examining survey data from the 2016 presidential election to correlations between voter concerns and voter behaviors. We will be examining how priorities of voters inform who they will voter for during an election."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d487c1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc73dbe7",
   "metadata": {},
   "source": [
    "# Importing Data and About the Data Set\n",
    "Here we important the data set from the csv file.\n",
    "Our dataset comes from a survey conducted by the non-paritsan Democracy Fund Voter Survey Group. The survey was conducted after the 2016 presidential election with the intent to  better understand voter interests and voting behavior across the United States. \n",
    "What follows is a data set with 668 features - each relaying different information about the voters surveyed including candidates voted for, demographic data, and public issue interest.\n",
    "We slim down this data both in features and number of data points down below so that it becomes more fit for machine learning models and focuses on the questions we want to answer with this data set.\n",
    "\n",
    "The main question we want to ask is: *Can we predict the presidential candidate a voter voted for based on their pplitical interest in public issues?* Our **Feature Selection** and **Data Cleaning** sections below explain how we extracted this data from the data set. Meanwhile our **Data Exploration** section below those provide statistical justification that there is indeed a correlation between public issue interests and presidential candidate that is worth exploring. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538a808f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"voter_survey_2016_data.csv\", engine='python')\n",
    "data.head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fe57a9",
   "metadata": {},
   "source": [
    "# Feature Selection\n",
    "We want to examine which issues matter to which party's voters. To examine this we will be looking at columns\n",
    "imiss_a_2016 - imiss_y_2016. These columns represent the surveyer's answers to questions where they were asked to rank how important a public issue was on a categorical scale: \"Very important\", \"Somewhat important, \"Not very important\", \"unimportant\". We will focus our data set on these columns so that our machine learning algorithm focuses purely on voter interest since that is what we're interested in investigating. We will also be including the column of who the surveyer voted for president as this will form the basis of our labels (presvote16post_2016). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61355c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def features(data, chosen_features):\n",
    "    columns_renamed = ['Crime', 'The Economy', 'Immigration', 'The Enviroment', 'Religious Liberty', 'Terrorism', 'Gay Rights', 'Education', 'Family and Medical Leave', 'Healthcare', 'Money in Politics', 'Climate Change', 'Social Security', 'Infrastructure Investment', 'Jobs', 'The Budget Deficit', 'Poverty', 'Taxes', 'Medicare', 'Abortion', 'Size of Goverment', 'Race Equality', 'Gender Equality', 'immi_contribution_2016', 'immi_naturalize_2016', 'immi_makedifficult_2016', 'immi_muslim_2016', 'abortview3_2016', 'gaymar_2016', 'view_transgender_2016', 'deathpen_2016', 'deathpenfreq_2016', 'police_threat_2016', 'univhealthcov_2016', 'healthreformbill_2016', 'envwarm_2016', 'envpoll2_2016', 'affirmact_gen_2016', 'taxdoug_2016', 'govt_reg_2016', 'gvmt_involment_2016', 'tradepolicy_2016', 'free_trade_1_2016', 'free_trade_2_2016', 'free_trade_3_2016', 'free_trade_4_2016']\n",
    "    return dataPrep(data, chosen_features, columns_renamed)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c460b2b2",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n",
    "We want to turn the data into something that we can easily use to train our models. We change our labels to: Hillary Clinton to 1, Donald Trump to 2, and all others are 0. We also transform the 23 question survey using One Hot Encoding because all of the responces are catigorical. We have also added results of questions about issues to the data set. The\n",
    "overall size of the dataset is about 8000 x 46, which will expand to 8000 x 173 with one hot encoding. We also dropped NaN values from the dataset. This decreased the number of datapoints to 5716. While a significant number of data points were lost, we still have a large number to use for our machin learning models so we believe this smaller sample size will not affect the results a significant amount. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27126ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dataPrep(data, columns, columns_renamed):\n",
    "    \n",
    "    df = pd.DataFrame(data=data, columns=columns)\n",
    "    \n",
    "    df.dropna(axis=0, inplace=True) #This drops all nans \n",
    "    labels = df['presvote16post_2016']\n",
    "    df = df.drop(['presvote16post_2016'], axis=1)\n",
    "    #df_clean = df.apply(lambda x: x.fillna(x.value_counts().index[0])) #this fills with mode of column\n",
    "    columns = ['Crime', 'The Economy', 'Immigration', 'The Enviroment', 'Religious Liberty', 'Terrorism', 'Gay Rights', 'Education', 'Family and Medical Leave', 'Healthcare', 'Money in Politics', 'Climate Change', 'Social Security', 'Infrastructure Investment', 'Jobs', 'The Budget Deficit', 'Poverty', 'Taxes', 'Medicare', 'Abortion', 'Size of Goverment', 'Race Equality', 'Gender Equality', 'immi_contribution_2016', 'immi_naturalize_2016', 'immi_makedifficult_2016', 'immi_muslim_2016', 'abortview3_2016', 'gaymar_2016', 'view_transgender_2016', 'deathpen_2016', 'deathpenfreq_2016', 'police_threat_2016', 'univhealthcov_2016', 'healthreformbill_2016', 'envwarm_2016', 'envpoll2_2016', 'affirmact_gen_2016', 'taxdoug_2016', 'govt_reg_2016', 'gvmt_involment_2016', 'tradepolicy_2016', 'free_trade_1_2016', 'free_trade_2_2016', 'free_trade_3_2016', 'free_trade_4_2016']\n",
    "    df.columns = columns\n",
    "    data_x = pd.get_dummies(df)\n",
    "    label = transformLabels(labels)\n",
    "    return label, data_x\n",
    "\n",
    "def transformLabels(temp):\n",
    "    label = []\n",
    "    for name in temp:\n",
    "        if name == \"Hillary Clinton\":\n",
    "            label.append(1)\n",
    "        elif name == \"Donald Trump\":\n",
    "            label.append(2)\n",
    "        elif name == \"Gary Johnson\":\n",
    "            label.append(3)\n",
    "        elif name == \"Jill Stein\":\n",
    "            label.append(4)\n",
    "        elif name == \"Evan McMullin\":\n",
    "            label.append(5)\n",
    "        else:\n",
    "            label.append(0)\n",
    "    return label\n",
    "\n",
    "chosen_features = ['presvote16post_2016', 'imiss_a_2016', 'imiss_b_2016', 'imiss_c_2016', 'imiss_d_2016', 'imiss_e_2016', 'imiss_f_2016', 'imiss_g_2016', 'imiss_h_2016', 'imiss_i_2016', 'imiss_j_2016', 'imiss_k_2016', 'imiss_l_2016', 'imiss_m_2016', 'imiss_n_2016', 'imiss_o_2016','imiss_p_2016', 'imiss_q_2016','imiss_r_2016','imiss_s_2016', 'imiss_t_2016','imiss_u_2016','imiss_x_2016','imiss_y_2016', 'immi_contribution_2016', 'immi_naturalize_2016', 'immi_makedifficult_2016', 'immi_muslim_2016', 'abortview3_2016', 'gaymar_2016', 'view_transgender_2016', 'deathpen_2016', 'deathpenfreq_2016', 'police_threat_2016', 'univhealthcov_2016', 'healthreformbill_2016', 'envwarm_2016', 'envpoll2_2016', 'affirmact_gen_2016', 'taxdoug_2016', 'govt_reg_2016', 'gvmt_involment_2016', 'tradepolicy_2016', 'free_trade_1_2016', 'free_trade_2_2016', 'free_trade_3_2016', 'free_trade_4_2016']\n",
    "label, data_x = features(data, chosen_features)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15cca5bf",
   "metadata": {},
   "source": [
    "# Data Exploration\n",
    "With an original data set with so many features, we decided it was best to focus on a subset of those features so we can hone in on a specific question about voter behavior. We decided to focus on public issue interest since this can help political candidates determine how to develop a platform during their campaigns if they are trying to appeal to a certain group of voters. We decided to avoid demographic information to keep our models focused on public interest and avoid profiling voters based on race, gender, and sexuality in our machine learning models since little information about what voters actually want in their politicans can be gained from that information.\n",
    "\n",
    "Before we go ahead with our machine learning models we should explore the data and see if the data concerning voter interest is appropriate for classifier data. We need to see if there is a correlation between voter interest and political candidate voted for. To do this, we provided a visual analysis of voter behavior using bar graphs and a chi squared test to see if a correlation exists. \n",
    "\n",
    "## Bar Graph Representations\n",
    "Below we can visually analyze this data through bar graphs. We have sorted the responses by label (presidential candidate voted for) and response to the first few questions of the survey where issues were ranked on the categorical scale: 'Very important', 'Somewhat important', 'Not very important', 'Unimportant'.\n",
    "\n",
    "Issues that are split across party lines can be seen visually via large gaps in the blue bar (Democrat voters) and red bars (Republican voters) in importance and whether the blue and red bars increase or decrease in size when moving along the x axis. For instance, social issues such as Gender Equality, Racial Equality, and Gay Rights have a large blue bar in the Very Important category, while the red bars are larger in the Not Very Important or Unimportant categories. Meanwhile issues of national security such as terrorism, immigration, and size of government have large red bars in the Very Important category while the blue bars are more evenly spaced out. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6c4dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataRelabeled(data):\n",
    "    \n",
    "    columns = ['presvote16post_2016', 'imiss_a_2016', 'imiss_b_2016', 'imiss_c_2016', 'imiss_d_2016', 'imiss_e_2016', 'imiss_f_2016', 'imiss_g_2016', 'imiss_h_2016', 'imiss_i_2016', 'imiss_j_2016', 'imiss_k_2016', 'imiss_l_2016', 'imiss_m_2016', 'imiss_n_2016', 'imiss_o_2016','imiss_p_2016', 'imiss_q_2016','imiss_r_2016','imiss_s_2016', 'imiss_t_2016','imiss_u_2016','imiss_x_2016','imiss_y_2016', 'immi_contribution_2016', 'immi_naturalize_2016', 'immi_makedifficult_2016', 'immi_muslim_2016', 'abortview3_2016', 'gaymar_2016', 'view_transgender_2016', 'deathpen_2016', 'deathpenfreq_2016', 'police_threat_2016', 'univhealthcov_2016', 'healthreformbill_2016', 'envwarm_2016', 'envpoll2_2016', 'affirmact_gen_2016', 'taxdoug_2016', 'govt_reg_2016', 'gvmt_involment_2016', 'tradepolicy_2016', 'free_trade_1_2016', 'free_trade_2_2016', 'free_trade_3_2016', 'free_trade_4_2016']\n",
    "    df = pd.DataFrame(data=data, columns=columns)\n",
    "    \n",
    "    df.dropna(axis=0, inplace=True) #This drops all nans \n",
    "    labels = df['presvote16post_2016']\n",
    "    df = df.drop(['presvote16post_2016'], axis=1)\n",
    "    columns = ['Crime', 'The Economy', 'Immigration', 'The Enviroment', 'Religious Liberty', 'Terrorism', 'Gay Rights', 'Education', 'Family and Medical Leave', 'Healthcare', 'Money in Politics', 'Climate Change', 'Social Security', 'Infrastructure Investment', 'Jobs', 'The Budget Deficit', 'Poverty', 'Taxes', 'Medicare', 'Abortion', 'Size of Goverment', 'Race Equality', 'Gender Equality', 'immi_contribution_2016', 'immi_naturalize_2016', 'immi_makedifficult_2016', 'immi_muslim_2016', 'abortview3_2016', 'gaymar_2016', 'view_transgender_2016', 'deathpen_2016', 'deathpenfreq_2016', 'police_threat_2016', 'univhealthcov_2016', 'healthreformbill_2016', 'envwarm_2016', 'envpoll2_2016', 'affirmact_gen_2016', 'taxdoug_2016', 'govt_reg_2016', 'gvmt_involment_2016', 'tradepolicy_2016', 'free_trade_1_2016', 'free_trade_2_2016', 'free_trade_3_2016', 'free_trade_4_2016']\n",
    "    df.columns = columns\n",
    "    label = transformLabels(labels)\n",
    "    return label, df\n",
    "\n",
    "def sortCounts(counts):\n",
    "    ret = [counts['Very important'], counts['Somewhat important'], counts['Not very important'], counts['Unimportant']]\n",
    "    return ret\n",
    "\n",
    "label, df_explore = dataRelabeled(data)\n",
    "columns_issues = ['Crime', 'The Economy', 'Immigration', 'The Enviroment', 'Religious Liberty', 'Terrorism', 'Gay Rights', 'Education', 'Family and Medical Leave', 'Healthcare', 'Money in Politics', 'Climate Change', 'Social Security', 'Infrastructure Investment', 'Jobs', 'The Budget Deficit', 'Poverty', 'Taxes', 'Medicare', 'Abortion', 'Size of Goverment', 'Race Equality', 'Gender Equality']\n",
    "df_explore['label'] = label\n",
    "df_explore.head()\n",
    "\n",
    "df_dem = df_explore.loc[df_explore['label']==1]\n",
    "df_rep = df_explore.loc[df_explore['label'] == 2]\n",
    "\n",
    "i = 1\n",
    "\n",
    "\n",
    "plt.subplots(5, 5, figsize=(20, 20))\n",
    "\n",
    "for c in columns_issues:\n",
    "    #group survey responses\n",
    "    counts_dem = df_dem.groupby([c]).size()\n",
    "    counts_rep = df_rep.groupby([c]).size()\n",
    " \n",
    "    #sort counts in decreasing order of importance\n",
    "    counts_dem = sortCounts(counts_dem)\n",
    "    counts_rep = sortCounts(counts_rep)\n",
    "\n",
    "    # build subplots\n",
    "    num_cats = df2[c].nunique()\n",
    "    X = np.arange(num_cats)\n",
    "    plt.subplot(5, 5, i)\n",
    "    plt.bar(X + 0.00, counts_dem, color = 'b', width = 0.25)\n",
    "    plt.bar(X + 0.25, counts_rep, color = 'r', width = 0.25)\n",
    "    categories = ['VI', 'SI', 'NVI', 'UI']\n",
    "    plt.xticks(X.tolist(), labels=categories)\n",
    "    plt.title(c)\n",
    "    plt.legend(labels=['Democrat','Republican'])\n",
    "    i += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a273ab94",
   "metadata": {},
   "source": [
    "## Chi Square Test\n",
    "To further demonstrate that there is a correlation between public issues and presidential candidate voted for, we can due a chi square test. The Chi Square Test for Independence measures whether two categories are independent or not. It starts with the null hypothesis \"The two categories are independent\". If, however, the p-value (a statistical measurement of the test), is less than a critical value of 0.05, we can reject the null hypothesis with a 95% confidence. Instead we accept the alternative hypothesis \"The two categories are dependent\". We can run this test on each public issue where we compare presidential candidate with survey response. If we reject the null hypothesis, that the two categories are independent, then that means there is a correlation between the two categories making this data fit for data mining models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4840f220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# track results of chi square tests\n",
    "num_rejected = 0\n",
    "num_approved = 0\n",
    "crit_val = 0.05\n",
    "\n",
    "df_explore_nolabel = df_explore.drop(['label'], axis=1)\n",
    "cols = df_explore.columns\n",
    "\n",
    "for c in cols:\n",
    "    contingency = pd.crosstab(df_explore[c], df_explore['label'])\n",
    "    c, p, dof, expected = sp.stats.chi2_contingency(contingency)\n",
    "    if(p <= 0.05):\n",
    "        num_rejected += 1\n",
    "    else:\n",
    "        num_approved += 1\n",
    "data_chi = {'Null Hypothesis': ['REJECTED', 'ACCEPTED'],\n",
    "            'Number of Survey Questions': [num_rejected, num_approved]}\n",
    "df_chi = pd.DataFrame(data_chi)\n",
    "df_chi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f57502",
   "metadata": {},
   "source": [
    "Note how after running the Chi Square Test between every survey questions answers and the presidential candidate category, the null hypothesis is rejected. Therefore, it is likely for each survey question that there is some correlation between survey answers and presidential candidate voted for. We can now proceed with confidence that this data can be used for machine learning models where survey answers can be used to predict presidential candidate voted for."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b15d22a",
   "metadata": {},
   "source": [
    "# Data Analysis\n",
    "Having sufficiently cleaned, engineered, and explored the data. We can now analyze our data set to test our question of *Can we predict the presidential candidate a voter voted for based on their pplitical interest in public issues?*\n",
    "\n",
    "We approach this by using the various classifier machine learning models we learned in class and see how accurate they are in correctly predicting the presidential candidate the voter voted for in 2016 based on their public issue interest. The different models we used are listed below with their accuracy in predicting a voter's presidential candidate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af5d433",
   "metadata": {},
   "source": [
    "## Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9e21bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "params = {\"max_depth\": list(range(10, 40, 5)), \"min_samples_leaf\": [5,10,15,20], \"max_features\": list(range(20, 160, 20))}\n",
    "\n",
    "tree = DecisionTreeClassifier()\n",
    "grid_search = GridSearchCV(tree, params, cv=5, scoring='accuracy')\n",
    "grid_search.fit(data_x, label)\n",
    "start = time.time()\n",
    "nested_score = cross_val_score(grid_search, data_x, label, cv=10)\n",
    "end = time.time()\n",
    "print(\"Accuracy:\", nested_score.mean()*100)\n",
    "print(\"time : \", end - start)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae018aa",
   "metadata": {},
   "source": [
    "## Naive Bayes (NB) & Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb057a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf = GaussianNB()\n",
    "clf.fit(data_x, label)\n",
    "\n",
    "nested_score = cross_val_score(clf, data_x, label, cv=10)\n",
    "print(\"Accuracy:\", nested_score.mean()*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aef432e",
   "metadata": {},
   "source": [
    "## k-Nearest Neighbor (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae169e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=7)\n",
    "pipe = Pipeline(steps=[(\"knn\", knn)])\n",
    "\n",
    "param_grid = {\n",
    "    'knn__n_neighbors': list(range(1, 50))\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid, cv=10)\n",
    "grid_search.fit(data_x,label)\n",
    "start = time.time()\n",
    "nested_score = cross_val_score(grid_search, data_x, label, cv=10)\n",
    "end = time.time()\n",
    "print(\"Accuracy:\", nested_score.mean()*100)\n",
    "print(\"time : \", end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cc2976",
   "metadata": {},
   "source": [
    "## NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a738138a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "nn = MLPClassifier()\n",
    "param_grid = {\n",
    "    'nn__hidden_layer_sizes': list(range(30, 100, 10)),\n",
    "    'nn__activation':['logical', 'tanh', 'relu']\n",
    "}\n",
    "\n",
    "pipe = Pipeline([(\"nn\", nn)])\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, cv=5, scoring ='accuracy')\n",
    "grid.fit(data_x, label)\n",
    "nested_score = cross_val_score(grid, data_x, label, cv=5)\n",
    "print(\"Accuracy:\", nested_score.mean()*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99511b4",
   "metadata": {},
   "source": [
    "## Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "de528166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 86.1264522878696\n"
     ]
    }
   ],
   "source": [
    "# your code goes here\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest = RandomForestClassifier()\n",
    "param_grid = {\n",
    "    'max_depth': list(range(30, 60, 5)),\n",
    "    'min_samples_leaf':[8,10,12, 14, 16],\n",
    "    'max_features':['sqrt','log2']\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(forest, param_grid, cv=5, scoring ='accuracy')\n",
    "grid.fit(data_x, label)\n",
    "nested_score = cross_val_score(grid, data_x, label, cv=5)\n",
    "print(\"Accuracy:\", nested_score.mean()*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0adfd5",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "be84ec9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 86.35383208217856\n"
     ]
    }
   ],
   "source": [
    "\n",
    "svm = SVC()\n",
    "pipe = Pipeline(steps=[(\"svc\", svm)])\n",
    "\n",
    "param_grid = {\n",
    "    'svc__kernel': ['linear', 'rbf', 'poly']\n",
    "}\n",
    "grid = GridSearchCV(pipe, param_grid, cv=5)\n",
    "grid.fit(data_x,label)\n",
    "\n",
    "nested_score = cross_val_score(grid, data_x, label, cv=5, scoring='accuracy')\n",
    "print(\"Accuracy:\", nested_score.mean()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04ec3ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
